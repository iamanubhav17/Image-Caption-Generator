{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed93a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4676813",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'C:/Users/91639/OneDrive/Desktop/Image/input'\n",
    "WORKING_DIR = 'C:/Users/91639/OneDrive/Desktop/Image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ef555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134260544 (512.16 MB)\n",
      "Trainable params: 134260544 (512.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load vgg16 model\n",
    "model = VGG16()\n",
    "# restructure the model\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "# summarize\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94c53501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ac88dfd7904a2893750e2c3bc92513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_1\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 224, 224, 3) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m image \u001b[38;5;241m=\u001b[39m preprocess_input(image)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# extract features\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# get image ID\u001b[39;00m\n\u001b[0;32m     18\u001b[0m image_id \u001b[38;5;241m=\u001b[39m img_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegwhgriw1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_1\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 224, 224, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# extract features from image\n",
    "features = {}\n",
    "directory = os.path.join(BASE_DIR, 'Images')\n",
    "\n",
    "for img_name in tqdm(os.listdir(directory)):\n",
    "    # load the image from file\n",
    "    img_path = directory + '/' + img_name\n",
    "    image = load_img(img_path, target_size=(224, 224))\n",
    "    # convert image pixels to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # reshape data for model\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    # preprocess image for vgg\n",
    "    image = preprocess_input(image)\n",
    "    # extract features\n",
    "    feature = model.predict(image, verbose=0)\n",
    "    # get image ID\n",
    "    image_id = img_name.split('.')[0]\n",
    "    # store feature\n",
    "    features[image_id] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cd8e8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter\n",
      "  Obtaining dependency information for jupyter from https://files.pythonhosted.org/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.1.2)\n",
      "Collecting notebook (from jupyter)\n",
      "  Obtaining dependency information for notebook from https://files.pythonhosted.org/packages/61/06/b4f53cf193765140f0b27094683dfae1b656d9f7264831ace7699420c1c7/notebook-7.1.2-py3-none-any.whl.metadata\n",
      "  Downloading notebook-7.1.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting qtconsole (from jupyter)\n",
      "  Obtaining dependency information for qtconsole from https://files.pythonhosted.org/packages/d5/21/0887c50fa5bca7bfde29f65999a6ac234617f2a007b6b387aa4dc0ca36a8/qtconsole-5.5.1-py3-none-any.whl.metadata\n",
      "  Downloading qtconsole-5.5.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Obtaining dependency information for jupyter-console from https://files.pythonhosted.org/packages/ca/77/71d78d58f15c22db16328a476426f7ac4a60d3a5a7ba3b9627ee2f7903d4/jupyter_console-6.6.3-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter)\n",
      "  Obtaining dependency information for nbconvert from https://files.pythonhosted.org/packages/23/8a/8d67cbd984739247e4b205c1143e2f71b25b4f71e180fe70f7cb2cf02633/nbconvert-7.16.3-py3-none-any.whl.metadata\n",
      "  Downloading nbconvert-7.16.3-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from jupyter) (6.25.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (5.10.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: backcall in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (8.3.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (5.3.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (1.5.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter) (22.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter) (6.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (4.11.1)\n",
      "Collecting bleach!=5.0.0 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for bleach!=5.0.0 from https://files.pythonhosted.org/packages/ea/63/da7237f805089ecc28a3f36bca6a21c31fcbc2eb380f3b8f1be3312abd14/bleach-6.1.0-py3-none-any.whl.metadata\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for defusedxml from https://files.pythonhosted.org/packages/07/6c/aa3f2f849e01cb6a001cd8554a88d4c77c5c1a31c95bdf1cf9301e6d9ef4/defusedxml-0.7.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (3.1.2)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for jupyterlab-pygments from https://files.pythonhosted.org/packages/b1/dd/ead9d8ea85bf202d90cc513b533f9c363121c7792674f78e0d8a854b63b4/jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (2.1.1)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for mistune<4,>=2.0.3 from https://files.pythonhosted.org/packages/f0/74/c95adcdf032956d9ef6c89a9b8a5152bf73915f8c633f3e3d88d06bd699c/mistune-3.0.2-py3-none-any.whl.metadata\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for nbclient>=0.5.0 from https://files.pythonhosted.org/packages/66/e8/00517a23d3eeaed0513e718fbc94aab26eaa1758f5690fc8578839791c79/nbclient-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for nbformat>=5.7 from https://files.pythonhosted.org/packages/a9/82/0340caa499416c78e5d8f5f05947ae4bc3cba53c9f038ab6e9ed964e22f1/nbformat-5.10.4-py3-none-any.whl.metadata\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for pandocfilters>=1.4.1 from https://files.pythonhosted.org/packages/ef/af/4fbc8cab944db5d21b7e2a5b8e9211a03a79852b1157e2c102fcc61ac440/pandocfilters-1.5.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for tinycss2 from https://files.pythonhosted.org/packages/da/99/fd23634d6962c2791fb8cb6ccae1f05dcbfc39bce36bba8b1c9a8d92eae8/tinycss2-1.2.1-py3-none-any.whl.metadata\n",
      "  Downloading tinycss2-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from notebook->jupyter)\n",
      "  Obtaining dependency information for jupyter-server<3,>=2.4.0 from https://files.pythonhosted.org/packages/95/85/483b8e09a897d1bc2194646d30d4ce6ae166106e91ecbd11d6b6d9ccfc36/jupyter_server-2.13.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_server-2.13.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyterlab-server<3,>=2.22.1 (from notebook->jupyter)\n",
      "  Obtaining dependency information for jupyterlab-server<3,>=2.22.1 from https://files.pythonhosted.org/packages/6a/c9/b270a875916b18f137bb30ecd05031a2f05c95d47a8e8fbd3f805a72f593/jupyterlab_server-2.26.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_server-2.26.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyterlab<4.2,>=4.1.1 (from notebook->jupyter)\n",
      "  Obtaining dependency information for jupyterlab<4.2,>=4.1.1 from https://files.pythonhosted.org/packages/4c/5a/e084a40e593329859926c5824cd47b32b2700732a179ca94b2c533c4dddf/jupyterlab-4.1.6-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab-4.1.6-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting notebook-shim<0.3,>=0.2 (from notebook->jupyter)\n",
      "  Obtaining dependency information for notebook-shim<0.3,>=0.2 from https://files.pythonhosted.org/packages/f9/33/bd5b9137445ea4b680023eb0469b2bb969d61303dedb2aac6560ff3d14a1/notebook_shim-0.2.4-py3-none-any.whl.metadata\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting qtpy>=2.4.0 (from qtconsole->jupyter)\n",
      "  Obtaining dependency information for qtpy>=2.4.0 from https://files.pythonhosted.org/packages/7e/a9/2146d5117ad8a81185331e0809a6b48933c10171f5bac253c6df9fce991c/QtPy-2.4.1-py3-none-any.whl.metadata\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert->jupyter)\n",
      "  Obtaining dependency information for webencodings from https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (2.6.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (305)\n",
      "Collecting anyio>=3.1.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for anyio>=3.1.0 from https://files.pythonhosted.org/packages/14/fd/2f20c40b45e4fb4324834aea24bd4afdf1143390242c0b33774da0e2e34f/anyio-4.3.0-py3-none-any.whl.metadata\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting argon2-cffi (from jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for argon2-cffi from https://files.pythonhosted.org/packages/a4/6a/e8a041599e78b6b3752da48000b14c8d1e8a04ded09c88c714ba047f34f5/argon2_cffi-23.1.0-py3-none-any.whl.metadata\n",
      "  Downloading argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for jupyter-events>=0.9.0 from https://files.pythonhosted.org/packages/a5/94/059180ea70a9a326e1815176b2370da56376da347a796f8c4f0b830208ef/jupyter_events-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyter-server-terminals (from jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for jupyter-server-terminals from https://files.pythonhosted.org/packages/07/2d/2b32cdbe8d2a602f697a649798554e4f072115438e92249624e532e8aca6/jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting overrides (from jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for overrides from https://files.pythonhosted.org/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl.metadata\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client (from jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for prometheus-client from https://files.pythonhosted.org/packages/c7/98/745b810d822103adca2df8decd4c0bbe839ba7ad3511af3f0d09692fc0f0/prometheus_client-0.20.0-py3-none-any.whl.metadata\n",
      "  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pywinpty (from jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for pywinpty from https://files.pythonhosted.org/packages/02/f0/2004a0c907eb74155b6fafa5801931d9e15d55905db6811f146cc2d145cd/pywinpty-2.0.13-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading pywinpty-2.0.13-cp311-none-win_amd64.whl.metadata (5.2 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for send2trash>=1.8.2 from https://files.pythonhosted.org/packages/40/b0/4562db6223154aa4e22f939003cb92514c79f3d4dccca3444253fd17f902/Send2Trash-1.8.3-py3-none-any.whl.metadata\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for terminado>=0.8.3 from https://files.pythonhosted.org/packages/6a/9e/2064975477fdc887e47ad42157e214526dcad8f317a948dee17e1659a62f/terminado-0.18.1-py3-none-any.whl.metadata\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client (from jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for websocket-client from https://files.pythonhosted.org/packages/1e/70/1e88138a9afbed1d37093b85f0bebc3011623c4f47c166431599fe9d6c93/websocket_client-1.7.0-py3-none-any.whl.metadata\n",
      "  Downloading websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter)\n",
      "  Obtaining dependency information for async-lru>=1.0.0 from https://files.pythonhosted.org/packages/fa/9f/3c3503693386c4b0f245eaf5ca6198e3b28879ca0a40bde6b0e319793453/async_lru-2.0.4-py3-none-any.whl.metadata\n",
      "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter)\n",
      "  Obtaining dependency information for httpx>=0.25.0 from https://files.pythonhosted.org/packages/41/7b/ddacf6dcebb42466abd03f368782142baa82e08fc0c1f8eaa05b4bae87d5/httpx-0.27.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter)\n",
      "  Obtaining dependency information for jupyter-lsp>=2.0.0 from https://files.pythonhosted.org/packages/07/e0/7bd7cff65594fd9936e2f9385701e44574fc7d721331ff676ce440b14100/jupyter_lsp-2.2.5-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for babel>=2.10 from https://files.pythonhosted.org/packages/0d/35/4196b21041e29a42dc4f05866d0c94fa26c9da88ce12c38c2265e42c82fb/Babel-2.14.0-py3-none-any.whl.metadata\n",
      "  Downloading Babel-2.14.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for json5>=0.9.0 from https://files.pythonhosted.org/packages/26/2f/f93ccd68858c0005445fbdad053417b7eaab87aaf31bd2b506a9005d0dfd/json5-0.9.24-py3-none-any.whl.metadata\n",
      "  Downloading json5-0.9.24-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for jsonschema>=4.18.0 from https://files.pythonhosted.org/packages/39/9d/b035d024c62c85f2e2d4806a59ca7b8520307f34e0932fbc8cc75fe7b2d9/jsonschema-4.21.1-py3-none-any.whl.metadata\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting requests>=2.31 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for requests>=2.31 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert->jupyter)\n",
      "  Obtaining dependency information for fastjsonschema>=2.15 from https://files.pythonhosted.org/packages/9c/b9/79691036d4a8f9857e74d1728b23f34f583b81350a27492edda58d5604e1/fastjsonschema-2.19.1-py3-none-any.whl.metadata\n",
      "  Downloading fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.3.2.post1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\91639\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook->jupyter) (2022.12.7)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook->jupyter)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/78/d4/e5d7e4f2174f8a4d63c8897d79eb8fe2503f7ecc03282fee1fa2719c2704/httpcore-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook->jupyter) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (22.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for jsonschema-specifications>=2023.03.6 from https://files.pythonhosted.org/packages/ee/07/44bd408781594c4d0a027666ef27fab1e441b109dc3b76b4f836f8fd04fe/jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/42/8e/ae1de7b12223986e949bdb886c004de7c304b6fa94de5b87c926c1099656/referencing-0.34.0-py3-none-any.whl.metadata\n",
      "  Downloading referencing-0.34.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for rpds-py>=0.7.1 from https://files.pythonhosted.org/packages/a8/de/68280c51afdb241111dec873dd7d457986adfd9fd5225494eee0c4a3b9a3/rpds_py-0.18.0-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading rpds_py-0.18.0-cp311-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for python-json-logger>=2.0.4 from https://files.pythonhosted.org/packages/35/a6/145655273568ee78a581e734cf35beb9e33a370b29c5d3c8fee3744de29f/python_json_logger-2.0.7-py3-none-any.whl.metadata\n",
      "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pyyaml>=5.3 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for pyyaml>=5.3 from https://files.pythonhosted.org/packages/b3/34/65bb4b2d7908044963ebf614fe0fdb080773fc7030d7e39c8d3eddcd4257/PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for rfc3339-validator from https://files.pythonhosted.org/packages/7b/44/4e421b96b67b2daff264473f7465db72fbdf36a07e05494f50300cc7b0c6/rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for rfc3986-validator>=0.1.1 from https://files.pythonhosted.org/packages/9e/51/17023c0f8f1869d8806b979a2bffa3f861f26a3f1a66b094288323fba52f/rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (1.26.13)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Obtaining dependency information for argon2-cffi-bindings from https://files.pythonhosted.org/packages/37/2c/e34e47c7dee97ba6f01a6203e0383e15b60fb85d78ac9a15cd066f6fe28b/argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl.metadata\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting fqdn (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for fqdn from https://files.pythonhosted.org/packages/cf/58/8acf1b3e91c58313ce5cb67df61001fc9dcd21be4fadb76c1a2d540e09ed/fqdn-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for isoduration from https://files.pythonhosted.org/packages/7b/55/e5326141505c5d5e34c5e0935d2908a74e4561eca44108fbfb9c13d2911a/isoduration-20.11.0-py3-none-any.whl.metadata\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for jsonpointer>1.13 from https://files.pythonhosted.org/packages/12/f6/0232cc0c617e195f06f810534d00b74d2f348fe71b2118009ad8ad31f878/jsonpointer-2.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting uri-template (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for uri-template from https://files.pythonhosted.org/packages/e7/00/3fca040d7cf8a32776d3d81a00c8ee7457e00f80c649f1e4a863c8321ae9/uri_template-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for webcolors>=1.11 from https://files.pythonhosted.org/packages/d5/e1/3e9013159b4cbb71df9bd7611cbf90dc2c621c8aeeb677fc41dad72f2261/webcolors-1.13-py3-none-any.whl.metadata\n",
      "  Downloading webcolors-1.13-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\91639\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.21)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for arrow>=0.15.0 from https://files.pythonhosted.org/packages/f8/ed/e97229a566617f2ae958a6b13e7cc0f585470eac730a73e9e82c32a3cdd2/arrow-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter)\n",
      "  Obtaining dependency information for types-python-dateutil>=2.8.10 from https://files.pythonhosted.org/packages/c7/1b/af4f4c4f3f7339a4b7eb3c0ab13416db98f8ac09de3399129ee5fdfa282b/types_python_dateutil-2.9.0.20240316-py3-none-any.whl.metadata\n",
      "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading nbconvert-7.16.3-py3-none-any.whl (257 kB)\n",
      "   ---------------------------------------- 0.0/257.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/257.4 kB 1.3 MB/s eta 0:00:01\n",
      "   --------- ----------------------------- 61.4/257.4 kB 812.7 kB/s eta 0:00:01\n",
      "   ---------- ---------------------------- 71.7/257.4 kB 558.5 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 112.6/257.4 kB 726.2 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 143.4/257.4 kB 708.1 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 153.6/257.4 kB 610.0 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/257.4 kB 692.9 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/257.4 kB 692.9 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/257.4 kB 692.9 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/257.4 kB 692.9 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/257.4 kB 692.9 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/257.4 kB 692.9 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/257.4 kB 692.9 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/257.4 kB 692.9 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/257.4 kB 692.9 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 204.8/257.4 kB 296.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 235.5/257.4 kB 320.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 257.4/257.4 kB 336.2 kB/s eta 0:00:00\n",
      "Downloading notebook-7.1.2-py3-none-any.whl (5.0 MB)\n",
      "   ---------------------------------------- 0.0/5.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.0 MB 960.0 kB/s eta 0:00:06\n",
      "   ---------------------------------------- 0.1/5.0 MB 1.1 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.1/5.0 MB 653.6 kB/s eta 0:00:08\n",
      "    --------------------------------------- 0.1/5.0 MB 798.9 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.2/5.0 MB 762.6 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.2/5.0 MB 748.1 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.2/5.0 MB 808.4 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.3/5.0 MB 785.2 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.0 MB 791.9 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.3/5.0 MB 805.1 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.4/5.0 MB 791.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.4/5.0 MB 823.4 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.0 MB 805.0 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.0 MB 832.7 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.5/5.0 MB 835.6 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.6/5.0 MB 841.6 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.6/5.0 MB 859.4 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.7/5.0 MB 860.2 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.7/5.0 MB 864.2 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.7/5.0 MB 878.1 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.8/5.0 MB 889.4 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.8/5.0 MB 888.5 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.9/5.0 MB 898.2 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.9/5.0 MB 897.0 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.0/5.0 MB 924.8 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.0/5.0 MB 926.7 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.1/5.0 MB 946.6 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.1/5.0 MB 952.4 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.2/5.0 MB 949.2 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.2/5.0 MB 970.6 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.3/5.0 MB 974.9 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.4/5.0 MB 986.4 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.4/5.0 MB 997.1 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.5/5.0 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.5/5.0 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.6/5.0 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.6/5.0 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.7/5.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 1.8/5.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 1.8/5.0 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.9/5.0 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.0/5.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.0/5.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.1/5.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.2/5.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.3/5.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.3/5.0 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 2.4/5.0 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 2.5/5.0 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 2.6/5.0 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.7/5.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.7/5.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.8/5.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.9/5.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.0/5.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.1/5.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.2/5.0 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.3/5.0 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.3/5.0 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.4/5.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 3.5/5.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 3.6/5.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 3.7/5.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.8/5.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.9/5.0 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.0/5.0 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.1/5.0 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.2/5.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.3/5.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.4/5.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.5/5.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.6/5.0 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.8/5.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.9/5.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.0/5.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.0/5.0 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
      "   ---------------------------------------- 0.0/123.4 kB ? eta -:--:--\n",
      "   ---------------------------------------  122.9/123.4 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 123.4/123.4 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.8/162.8 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading jupyter_server-2.13.0-py3-none-any.whl (383 kB)\n",
      "   ---------------------------------------- 0.0/383.2 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 194.6/383.2 kB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 317.4/383.2 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 383.2/383.2 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading jupyterlab-4.1.6-py3-none-any.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.4 MB 5.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.3/11.4 MB 4.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.5/11.4 MB 3.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/11.4 MB 3.8 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.8/11.4 MB 3.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.9/11.4 MB 3.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.1/11.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.2/11.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.4/11.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.5/11.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.7/11.4 MB 3.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.9/11.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.9/11.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.9/11.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.9/11.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.1/11.4 MB 3.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.3/11.4 MB 3.2 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.4/11.4 MB 3.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/11.4 MB 3.2 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.4 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.0/11.4 MB 3.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.2/11.4 MB 3.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.3/11.4 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.6/11.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.8/11.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.9/11.4 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.1/11.4 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.4/11.4 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.6/11.4 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.8/11.4 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.4 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.4/11.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.7/11.4 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.9/11.4 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.1/11.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.4 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.4 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.1/11.4 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.4/11.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.5/11.4 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.8/11.4 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.1/11.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.4 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.0/11.4 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.2/11.4 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.6/11.4 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.9/11.4 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.4 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.8/11.4 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.1/11.4 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_server-2.26.0-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.1/59.1 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/48.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.0/48.0 kB ? eta 0:00:00\n",
      "Downloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
      "Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "   ---------------------------------------- 0.0/93.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 93.5/93.5 kB ? eta 0:00:00\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.6/85.6 kB ? eta 0:00:00\n",
      "Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading Babel-2.14.0-py3-none-any.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 14.2 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.9/11.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.1/11.0 MB 8.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 3.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.9/11.0 MB 3.2 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.2/11.0 MB 3.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.7/11.0 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.3/11.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.7/11.0 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.0/11.0 MB 4.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.4/11.0 MB 5.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.0 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.6/11.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.0/11.0 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.5/11.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.0/11.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.5/11.0 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.9/77.9 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading json5-0.9.24-py3-none-any.whl (30 kB)\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.5/85.5 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "   ---------------------------------------- 0.0/69.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 69.1/69.1 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.6/62.6 kB ? eta 0:00:00\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading pywinpty-2.0.13-cp311-none-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.7/1.4 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.3/1.4 MB 16.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 14.8 MB/s eta 0:00:00\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 54.5/54.5 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.5/58.5 kB ? eta 0:00:00\n",
      "Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "   ---------------------------------------- 0.0/144.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 144.7/144.7 kB ? eta 0:00:00\n",
      "Downloading referencing-0.34.0-py3-none-any.whl (26 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rpds_py-0.18.0-cp311-none-win_amd64.whl (206 kB)\n",
      "   ---------------------------------------- 0.0/206.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 206.7/206.7 kB ? eta 0:00:00\n",
      "Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading webcolors-1.13-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.4/66.4 kB ? eta 0:00:00\n",
      "Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
      "Installing collected packages: webencodings, fastjsonschema, websocket-client, webcolors, uri-template, types-python-dateutil, tinycss2, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, requests, qtpy, pyyaml, pywinpty, python-json-logger, prometheus-client, pandocfilters, overrides, mistune, jupyterlab-pygments, jsonpointer, json5, httpcore, fqdn, defusedxml, bleach, babel, async-lru, anyio, terminado, referencing, httpx, arrow, argon2-cffi-bindings, jupyter-server-terminals, jsonschema-specifications, isoduration, argon2-cffi, jsonschema, qtconsole, nbformat, jupyter-console, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.17.3\n",
      "    Uninstalling jsonschema-4.17.3:\n",
      "      Successfully uninstalled jsonschema-4.17.3\n",
      "Successfully installed anyio-4.3.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 async-lru-2.0.4 babel-2.14.0 bleach-6.1.0 defusedxml-0.7.1 fastjsonschema-2.19.1 fqdn-1.5.1 httpcore-1.0.5 httpx-0.27.0 isoduration-20.11.0 json5-0.9.24 jsonpointer-2.4 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 jupyter-1.0.0 jupyter-console-6.6.3 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.13.0 jupyter-server-terminals-0.5.3 jupyterlab-4.1.6 jupyterlab-pygments-0.3.0 jupyterlab-server-2.26.0 mistune-3.0.2 nbclient-0.10.0 nbconvert-7.16.3 nbformat-5.10.4 notebook-7.1.2 notebook-shim-0.2.4 overrides-7.7.0 pandocfilters-1.5.1 prometheus-client-0.20.0 python-json-logger-2.0.7 pywinpty-2.0.13 pyyaml-6.0.1 qtconsole-5.5.1 qtpy-2.4.1 referencing-0.34.0 requests-2.31.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.18.0 send2trash-1.8.3 terminado-0.18.1 tinycss2-1.2.1 types-python-dateutil-2.9.0.20240316 uri-template-1.3.0 webcolors-1.13 webencodings-0.5.1 websocket-client-1.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/nbclient/\n",
      "  WARNING: The script wsdump.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script send2trash.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script qtpy.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pyjson5.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pybabel.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jsonschema.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-trust.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-console.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-execute.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-events.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter-dejavu.exe and jupyter-nbconvert.exe are installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-server.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jlpm.exe, jupyter-lab.exe, jupyter-labextension.exe and jupyter-labhub.exe are installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-notebook.exe is installed in 'c:\\Users\\91639\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61556e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store features in pickle\n",
    "pickle.dump(features, open(os.path.join(WORKING_DIR, 'features.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6a587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features from pickle\n",
    "with open(os.path.join(WORKING_DIR, 'features.pkl'), 'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb0ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_DIR, 'captions.txt'), 'r') as f:\n",
    "    next(f)\n",
    "    captions_doc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "196cdba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3476d282af4271bae1c8742a11e49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create mapping of image to captions\n",
    "mapping = {}\n",
    "# process lines\n",
    "for line in tqdm(captions_doc.split('\\n')):\n",
    "    # split the line by comma(,)\n",
    "    tokens = line.split(',')\n",
    "    if len(line) < 2:\n",
    "        continue\n",
    "    image_id, caption = tokens[0], tokens[1:]\n",
    "    # remove extension from image ID\n",
    "    image_id = image_id.split('.')[0]\n",
    "    # convert caption list to string\n",
    "    caption = \" \".join(caption)\n",
    "    # create list if needed\n",
    "    if image_id not in mapping:\n",
    "        mapping[image_id] = []\n",
    "    # store the caption\n",
    "    mapping[image_id].append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8fe68b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8091"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac27152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(mapping):\n",
    "    for key, captions in mapping.items():\n",
    "        for i in range(len(captions)):\n",
    "            # take one caption at a time\n",
    "            caption = captions[i]\n",
    "            # preprocessing steps\n",
    "            # convert to lowercase\n",
    "            caption = caption.lower()\n",
    "            # delete digits, special chars, etc., \n",
    "            caption = caption.replace('[^A-Za-z]', '')\n",
    "            # delete additional spaces\n",
    "            caption = caption.replace('\\s+', ' ')\n",
    "            # add start and end tags to the caption\n",
    "            caption = 'startseq ' + \" \".join([word for word in caption.split() if len(word)>1]) + ' endseq'\n",
    "            captions[i] = caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a7dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A child in a pink dress is climbing up a set of stairs in an entry way .',\n",
       " 'A girl going into a wooden building .',\n",
       " 'A little girl climbing into a wooden playhouse .',\n",
       " 'A little girl climbing the stairs to her playhouse .',\n",
       " 'A little girl in a pink dress going into a wooden cabin .']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before preprocess of text\n",
    "mapping['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b027a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c70bb613",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmapping\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1000268201_693b08cb0e\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mapping' is not defined"
     ]
    }
   ],
   "source": [
    "mapping['1000268201_693b08cb0e']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50c84503",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_captions = []\n",
    "for key in mapping:\n",
    "    for caption in mapping[key]:\n",
    "        all_captions.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4014df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40455"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad71e398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq child in pink dress is climbing up set of stairs in an entry way endseq',\n",
       " 'startseq girl going into wooden building endseq',\n",
       " 'startseq little girl climbing into wooden playhouse endseq',\n",
       " 'startseq little girl climbing the stairs to her playhouse endseq',\n",
       " 'startseq little girl in pink dress going into wooden cabin endseq',\n",
       " 'startseq black dog and spotted dog are fighting endseq',\n",
       " 'startseq black dog and tri-colored dog playing with each other on the road endseq',\n",
       " 'startseq black dog and white dog with brown spots are staring at each other in the street endseq',\n",
       " 'startseq two dogs of different breeds looking at each other on the road endseq',\n",
       " 'startseq two dogs on pavement moving toward each other endseq']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_captions[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f995c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a859784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get maximum length of the caption available\n",
    "max_length = max(len(caption.split()) for caption in all_captions)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b886990",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = list(mapping.keys())\n",
    "split = int(len(image_ids) * 0.90)\n",
    "train = image_ids[:split]\n",
    "test = image_ids[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e45bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generator to get data in batch (avoids session crash)\n",
    "def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
    "    # loop over images\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n = 0\n",
    "    while 1:\n",
    "        for key in data_keys:\n",
    "            n += 1\n",
    "            captions = mapping[key]\n",
    "            # process each caption\n",
    "            for caption in captions:\n",
    "                # encode the sequence\n",
    "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "                # split the sequence into X, y pairs\n",
    "                for i in range(1, len(seq)):\n",
    "                    # split into input and output pairs\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    # pad input sequence\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                    # encode output sequence\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                    # store the sequences\n",
    "                    X1.append(features[key][0])\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "                if n == batch_size:\n",
    "                    X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "                    yield [X1, X2], y\n",
    "                    X1, X2, y = list(), list(), list()\n",
    "                    n = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# encoder model\n",
    "# image feature layers\n",
    "inputs1 = Input(shape=(4096,))\n",
    "fe1 = Dropout(0.4)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "# sequence feature layers\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.4)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "\n",
    "# decoder model\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# plot the model\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a7141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91639\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "227/227 [==============================] - 342s 1s/step - loss: 5.2226\n",
      "227/227 [==============================] - 327s 1s/step - loss: 4.0150\n",
      "227/227 [==============================] - 329s 1s/step - loss: 3.5960\n",
      "227/227 [==============================] - 330s 1s/step - loss: 3.3338\n",
      "227/227 [==============================] - 330s 1s/step - loss: 3.1367\n",
      "227/227 [==============================] - 361s 2s/step - loss: 2.9921\n",
      "227/227 [==============================] - 412s 2s/step - loss: 2.8752\n",
      "227/227 [==============================] - 404s 2s/step - loss: 2.7782\n",
      "227/227 [==============================] - 402s 2s/step - loss: 2.6910\n",
      "227/227 [==============================] - 336s 1s/step - loss: 2.6207\n",
      "227/227 [==============================] - 320s 1s/step - loss: 2.5560\n",
      "227/227 [==============================] - 350s 2s/step - loss: 2.5026\n",
      "227/227 [==============================] - 408s 2s/step - loss: 2.4541\n",
      "227/227 [==============================] - 402s 2s/step - loss: 2.4048\n",
      "227/227 [==============================] - 402s 2s/step - loss: 2.3617\n",
      "227/227 [==============================] - 403s 2s/step - loss: 2.3196\n",
      "227/227 [==============================] - 395s 2s/step - loss: 2.2810\n",
      "227/227 [==============================] - 394s 2s/step - loss: 2.2467\n",
      "227/227 [==============================] - 397s 2s/step - loss: 2.2141\n",
      "227/227 [==============================] - 402s 2s/step - loss: 2.1849\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "steps = len(train) // batch_size\n",
    "\n",
    "for i in range(epochs):\n",
    "    # create data generator\n",
    "    generator = data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
    "    # fit for one epoch\n",
    "    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# model.save(WORKING_DIR+'/best_model.h5')\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\91639\\\\OneDrive\\\\Desktop\\\\Image')\n",
    "model.save('best_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fd32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e97691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28abf23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a690a804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28e400c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37bc0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model(\"C:\\\\Users\\\\91639\\\\OneDrive\\\\Desktop\\\\Image\\\\best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_word(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c41b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate caption for an image\n",
    "def predict_caption(model, image, tokenizer, max_length):\n",
    "    # add start tag for generation process\n",
    "    in_text = 'startseq'\n",
    "    # iterate over the max length of sequence\n",
    "    for i in range(max_length):\n",
    "        # encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pad the sequence\n",
    "        sequence = pad_sequences([sequence], max_length)\n",
    "        # predict next word\n",
    "        yhat = model.predict([image, sequence], verbose=0)\n",
    "        # get index with high probability\n",
    "        yhat = np.argmax(yhat)\n",
    "        # convert index to word\n",
    "        word = idx_to_word(yhat, tokenizer)\n",
    "        # stop if word not found\n",
    "        if word is None:\n",
    "            break\n",
    "        # append word as input for generating next word\n",
    "        in_text += \" \" + word\n",
    "        # stop if we reach end tag\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe1739ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    # Load the image from the file path\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    \n",
    "    # Convert the image to a numpy array\n",
    "    image_array = img_to_array(image)\n",
    "    \n",
    "    # Reshape the image array to match the expected input shape of your model\n",
    "    image_array = image_array.reshape((1, image_array.shape[0], image_array.shape[1], image_array.shape[2]))\n",
    "    \n",
    "    # Preprocess the image array (normalize pixel values and apply any other necessary preprocessing)\n",
    "    preprocessed_image = preprocess_input(image_array)\n",
    "    \n",
    "    return preprocessed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9566ed2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m91639\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msunset.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Generate the caption for the sample image\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m caption \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_caption_for_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Print the generated caption\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Caption:\u001b[39m\u001b[38;5;124m\"\u001b[39m, caption)\n",
      "Cell \u001b[1;32mIn[41], line 43\u001b[0m, in \u001b[0;36mgenerate_caption_for_image\u001b[1;34m(model, tokenizer, max_length, image_features)\u001b[0m\n\u001b[0;32m     40\u001b[0m image_features_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(image_features)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Predict the next word\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_features_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m yhat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(yhat)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Convert the index to a word\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:962\u001b[0m, in \u001b[0;36mTensorShape.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v2_behavior:\n\u001b[1;32m--> 962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dims\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    963\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[key]\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define the function to load and preprocess the image\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "# Define the function to extract features using a pre-trained CNN model\n",
    "def extract_features(image_path):\n",
    "    image = load_and_preprocess_image(image_path)\n",
    "    model = VGG16(weights='imagenet', include_top=True)\n",
    "    feature_extractor = Model(inputs=model.input, outputs=model.get_layer('fc2').output)\n",
    "    image_features = feature_extractor.predict(image.reshape((1, *image.shape)))\n",
    "    return image_features\n",
    "\n",
    "# Define the function to generate a caption for a single image\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function to generate a caption for a single image\n",
    "def generate_caption_for_image(model, tokenizer, max_length, image_features):\n",
    "    # Initialize the caption with the start token\n",
    "    in_text = 'startseq'\n",
    "    \n",
    "    # Iterate over the maximum length of the sequence\n",
    "    for _ in range(max_length):\n",
    "        # Tokenize the input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        \n",
    "        # Pad the sequence to the maximum length\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length, padding='post')\n",
    "        \n",
    "        # Convert image features to a TensorFlow Tensor\n",
    "        image_features_tensor = tf.convert_to_tensor(image_features)\n",
    "        \n",
    "        # Predict the next word\n",
    "        yhat = model.predict([image_features_tensor, sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        \n",
    "        # Convert the index to a word\n",
    "        word = idx_to_word(yhat, tokenizer)\n",
    "        \n",
    "        # Stop if the word is None or the end token is encountered\n",
    "        if word is None or word == 'endseq':\n",
    "            break\n",
    "        \n",
    "        # Append the word to the input for the next iteration\n",
    "        in_text += ' ' + word\n",
    "    \n",
    "    return in_text\n",
    "\n",
    "# Define the sample image path\n",
    "image_path = 'C:\\\\Users\\\\91639\\\\OneDrive\\\\Desktop\\\\Image\\\\sunset.jpg'\n",
    "\n",
    "# Generate the caption for the sample image\n",
    "caption = generate_caption_for_image(model, tokenizer, max_length, image_path)\n",
    "\n",
    "# Print the generated caption\n",
    "print(\"Generated Caption:\", caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f8f9f26",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not ellipsis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example incorrect usage of ellipsis\u001b[39;00m\n\u001b[0;32m      2\u001b[0m arr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# Incorrect usage of ellipsis\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Example correct usage with integer index\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(arr[\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# Accessing the element at index 2\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not ellipsis"
     ]
    }
   ],
   "source": [
    "# Example incorrect usage of ellipsis\n",
    "arr = [1, 2, 3, 4, 5]\n",
    "print(arr[...])  # Incorrect usage of ellipsis\n",
    "\n",
    "# Example correct usage with integer index\n",
    "print(arr[2])  # Accessing the element at index 2\n",
    "\n",
    "# Example correct usage with slice\n",
    "print(arr[:3])  # Accessing the first three elements using slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3a760b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8989cab6574c8390eadb9b2870e8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/810 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'436015762_8d0bae90c3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m captions \u001b[38;5;241m=\u001b[39m mapping[key]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# predict the caption for image\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predict_caption(model, \u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m, tokenizer, max_length)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# split into words\u001b[39;00m\n\u001b[0;32m     11\u001b[0m actual_captions \u001b[38;5;241m=\u001b[39m [caption\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mfor\u001b[39;00m caption \u001b[38;5;129;01min\u001b[39;00m captions]\n",
      "\u001b[1;31mKeyError\u001b[0m: '436015762_8d0bae90c3'"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "# validate with test data\n",
    "actual, predicted = list(), list()\n",
    "\n",
    "for key in tqdm(test):\n",
    "    # get actual caption\n",
    "    captions = mapping[key]\n",
    "    # predict the caption for image\n",
    "    y_pred = predict_caption(model, features[key], tokenizer, max_length)\n",
    "    # split into words\n",
    "    actual_captions = [caption.split() for caption in captions]\n",
    "    y_pred = y_pred.split()\n",
    "    # append to the list\n",
    "    actual.append(actual_captions)\n",
    "    predicted.append(y_pred)\n",
    "    # calcuate BLEU score\n",
    "    print(\"BLEU-1: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print(\"BLEU-2: %f\" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c1d0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_caption(image_name):\n",
    "    # load the image\n",
    "    # image_name = \"1001773457_577c3a7d70.jpg\"\n",
    "    image_id = image_name.split('.')[0]\n",
    "    img_path = os.path.join(BASE_DIR, \"Images\", image_name)\n",
    "    image = Image.open(img_path)\n",
    "    captions = mapping[image_id]\n",
    "    print('---------------------Actual---------------------')\n",
    "    for caption in captions:\n",
    "        print(caption)\n",
    "    # predict the caption\n",
    "    y_pred = predict_caption(model, features[image_id], tokenizer, max_length)\n",
    "    print('--------------------Predicted--------------------')\n",
    "    print(y_pred)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "410d065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Actual---------------------\n",
      "A black dog and a spotted dog are fighting\n",
      "A black dog and a tri-colored dog playing with each other on the road .\n",
      "A black dog and a white dog with brown spots are staring at each other in the street .\n",
      "Two dogs of different breeds looking at each other on the road .\n",
      "Two dogs on pavement moving toward each other .\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1001773457_577c3a7d70'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_caption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1001773457_577c3a7d70.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 14\u001b[0m, in \u001b[0;36mgenerate_caption\u001b[1;34m(image_name)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(caption)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# predict the caption\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predict_caption(model, \u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_id\u001b[49m\u001b[43m]\u001b[49m, tokenizer, max_length)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------------Predicted--------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n",
      "\u001b[1;31mKeyError\u001b[0m: '1001773457_577c3a7d70'"
     ]
    }
   ],
   "source": [
    "generate_caption(\"1001773457_577c3a7d70.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5eb1a44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Actual---------------------\n",
      "A little girl covered in paint sits in front of a painted rainbow with her hands in a bowl .\n",
      "A little girl is sitting in front of a large painted rainbow .\n",
      "A small girl in the grass plays with fingerpaints in front of a white canvas with a rainbow on it .\n",
      "There is a girl with pigtails sitting in front of a rainbow painting .\n",
      "Young girl with pigtails painting outside in the grass .\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1002674143_1b742ab4b8'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_caption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1002674143_1b742ab4b8.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 14\u001b[0m, in \u001b[0;36mgenerate_caption\u001b[1;34m(image_name)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(caption)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# predict the caption\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predict_caption(model, \u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_id\u001b[49m\u001b[43m]\u001b[49m, tokenizer, max_length)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------------Predicted--------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n",
      "\u001b[1;31mKeyError\u001b[0m: '1002674143_1b742ab4b8'"
     ]
    }
   ],
   "source": [
    "generate_caption(\"1002674143_1b742ab4b8.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a564f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with real life pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5899f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16() \n",
    "# restructure the model\n",
    "vgg_model = Model(inputs=vgg_model.inputs,             \n",
    "                  outputs=vgg_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c730a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m feature \u001b[38;5;241m=\u001b[39m vgg_model\u001b[38;5;241m.\u001b[39mpredict(image, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# predict from the trained model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m predict_caption(model, feature, \u001b[43mtokenizer\u001b[49m, max_length)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "image_path = 'C:\\\\Users\\\\91639\\\\OneDrive\\\\Desktop\\\\sunset.jpg'\n",
    "# load image\n",
    "image = load_img(image_path, target_size=(224, 224))\n",
    "# convert image pixels to numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# preprocess image from vgg\n",
    "image = preprocess_input(image)\n",
    "# extract features\n",
    "feature = vgg_model.predict(image, verbose=0)\n",
    "# predict from the trained model\n",
    "predict_caption(model, feature, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facf702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2e694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c48d1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae0487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa627d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
